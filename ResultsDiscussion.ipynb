{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Final Project Results & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# American Sign Language Recognition\n",
    "\n",
    "# Names\n",
    "\n",
    "- Allen Phu\n",
    "- Kevin Yu\n",
    "- Saksham Rai\n",
    "- Rodrigo Lizaran-Molina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results/Discussion\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "### Main Takeaways\n",
    "After working through this project, we've realized that, ultimately, unsupervised algorithms were not that great for this dataset. This checks out with what we suspected before we began: unsupervised algorithms perform far worse than supervised algorithms for image recognition. \n",
    "\n",
    "While our supervised models such as SVM and CNN gave us great results, our unsupervised algorithms such as Gaussian Mixture Models and K-Means gave us poor performance. Unsurprisingly, the CNN gave us the best performance, with SVM coming in at second. This was expected, as CNN algorithms already have a reputation for being strong algorithms for image processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "pal = sns.color_palette(\"hls\", 10)\n",
    "\n",
    "import sklearn.cluster as cluster\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, classification_report, silhouette_score, accuracy_score, rand_score\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/sign_mnist_train.csv\")\n",
    "test = pd.read_csv(\"data/sign_mnist_test.csv\")\n",
    "\n",
    "extract_test = test.drop(columns=\"label\")\n",
    "test_data = extract_test.values\n",
    "test_labels = test.get(\"label\")\n",
    "\n",
    "extract_forkmeans = train.drop(columns=\"label\")\n",
    "data = extract_forkmeans.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - Results\n",
    "Our CNN gave us, by far, the best results. As has been stated before, supervised algorithms are better for image recognition. CNNs in particular are excellent (and mainly used) for image recognition, so the results didn't surprise us all too much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv2): Conv2d(15, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=180, out_features=100, bias=True)\n",
       "  (fc3): Linear(in_features=100, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(batch_size, 1, 28, 28)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 15, 3, 1, 1)\n",
    "        self.pool = nn.AvgPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(15, 20, 3,1,1)\n",
    "        self.conv3 = nn.Conv2d(20, 20, 3,1,1)\n",
    "        self.fc1 = nn.Linear(180, 100)\n",
    "        \n",
    "        self.fc3 = nn.Linear(100, 26)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "net = Net()     \n",
    "net.to(device)  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()  \n",
    "opt = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(train.get(\"label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 3.307\n",
      "[1,   200] loss: 3.117\n",
      "[1,   300] loss: 2.698\n",
      "[1,   400] loss: 2.308\n",
      "[1,   500] loss: 2.029\n",
      "[1,   600] loss: 1.773\n",
      "[1,   700] loss: 1.596\n",
      "[1,   800] loss: 1.471\n",
      "[1,   900] loss: 1.295\n",
      "[1,  1000] loss: 1.166\n",
      "[1,  1100] loss: 1.162\n",
      "[1,  1200] loss: 1.143\n",
      "[1,  1300] loss: 0.885\n",
      "[1,  1400] loss: 0.894\n",
      "[1,  1500] loss: 0.820\n",
      "[1,  1600] loss: 0.708\n",
      "[1,  1700] loss: 0.761\n",
      "[1,  1800] loss: 0.764\n",
      "[1,  1900] loss: 0.507\n",
      "[1,  2000] loss: 0.576\n",
      "[1,  2100] loss: 0.530\n",
      "[1,  2200] loss: 0.593\n",
      "[1,  2300] loss: 0.437\n",
      "[1,  2400] loss: 0.408\n",
      "[1,  2500] loss: 0.545\n",
      "[1,  2600] loss: 0.431\n",
      "[1,  2700] loss: 0.438\n",
      "[1,  2800] loss: 0.407\n",
      "[1,  2900] loss: 0.438\n",
      "[1,  3000] loss: 0.378\n",
      "[1,  3100] loss: 0.319\n",
      "[1,  3200] loss: 0.361\n",
      "[1,  3300] loss: 0.294\n",
      "[1,  3400] loss: 0.247\n",
      "[1,  3500] loss: 0.294\n",
      "[1,  3600] loss: 0.261\n",
      "[1,  3700] loss: 0.282\n",
      "[1,  3800] loss: 0.319\n",
      "[1,  3900] loss: 0.201\n",
      "[1,  4000] loss: 0.199\n",
      "[1,  4100] loss: 0.189\n",
      "[1,  4200] loss: 0.209\n",
      "[1,  4300] loss: 0.203\n",
      "[1,  4400] loss: 0.130\n",
      "[1,  4500] loss: 0.113\n",
      "[1,  4600] loss: 0.274\n",
      "[1,  4700] loss: 0.282\n",
      "[1,  4800] loss: 0.231\n",
      "[1,  4900] loss: 0.114\n",
      "[1,  5000] loss: 0.260\n",
      "[1,  5100] loss: 0.264\n",
      "[1,  5200] loss: 0.186\n",
      "[1,  5300] loss: 0.089\n",
      "[1,  5400] loss: 0.114\n",
      "[1,  5500] loss: 0.218\n",
      "[1,  5600] loss: 0.177\n",
      "[1,  5700] loss: 0.156\n",
      "[1,  5800] loss: 0.173\n",
      "[1,  5900] loss: 0.177\n",
      "[1,  6000] loss: 0.142\n",
      "[1,  6100] loss: 0.141\n",
      "[1,  6200] loss: 0.179\n",
      "[1,  6300] loss: 0.062\n",
      "[1,  6400] loss: 0.104\n",
      "[1,  6500] loss: 0.092\n",
      "[1,  6600] loss: 0.245\n",
      "[1,  6700] loss: 0.137\n",
      "[1,  6800] loss: 0.078\n",
      "[2,   100] loss: 0.066\n",
      "[2,   200] loss: 0.078\n",
      "[2,   300] loss: 0.159\n",
      "[2,   400] loss: 0.117\n",
      "[2,   500] loss: 0.041\n",
      "[2,   600] loss: 0.066\n",
      "[2,   700] loss: 0.186\n",
      "[2,   800] loss: 0.187\n",
      "[2,   900] loss: 0.110\n",
      "[2,  1000] loss: 0.075\n",
      "[2,  1100] loss: 0.080\n",
      "[2,  1200] loss: 0.129\n",
      "[2,  1300] loss: 0.123\n",
      "[2,  1400] loss: 0.048\n",
      "[2,  1500] loss: 0.064\n",
      "[2,  1600] loss: 0.141\n",
      "[2,  1700] loss: 0.078\n",
      "[2,  1800] loss: 0.118\n",
      "[2,  1900] loss: 0.127\n",
      "[2,  2000] loss: 0.084\n",
      "[2,  2100] loss: 0.038\n",
      "[2,  2200] loss: 0.057\n",
      "[2,  2300] loss: 0.083\n",
      "[2,  2400] loss: 0.118\n",
      "[2,  2500] loss: 0.108\n",
      "[2,  2600] loss: 0.059\n",
      "[2,  2700] loss: 0.062\n",
      "[2,  2800] loss: 0.096\n",
      "[2,  2900] loss: 0.214\n",
      "[2,  3000] loss: 0.042\n",
      "[2,  3100] loss: 0.096\n",
      "[2,  3200] loss: 0.091\n",
      "[2,  3300] loss: 0.144\n",
      "[2,  3400] loss: 0.178\n",
      "[2,  3500] loss: 0.058\n",
      "[2,  3600] loss: 0.041\n",
      "[2,  3700] loss: 0.010\n",
      "[2,  3800] loss: 0.026\n",
      "[2,  3900] loss: 0.105\n",
      "[2,  4000] loss: 0.065\n",
      "[2,  4100] loss: 0.054\n",
      "[2,  4200] loss: 0.057\n",
      "[2,  4300] loss: 0.038\n",
      "[2,  4400] loss: 0.019\n",
      "[2,  4500] loss: 0.026\n",
      "[2,  4600] loss: 0.087\n",
      "[2,  4700] loss: 0.196\n",
      "[2,  4800] loss: 0.104\n",
      "[2,  4900] loss: 0.046\n",
      "[2,  5000] loss: 0.077\n",
      "[2,  5100] loss: 0.139\n",
      "[2,  5200] loss: 0.083\n",
      "[2,  5300] loss: 0.124\n",
      "[2,  5400] loss: 0.069\n",
      "[2,  5500] loss: 0.032\n",
      "[2,  5600] loss: 0.045\n",
      "[2,  5700] loss: 0.016\n",
      "[2,  5800] loss: 0.042\n",
      "[2,  5900] loss: 0.088\n",
      "[2,  6000] loss: 0.143\n",
      "[2,  6100] loss: 0.034\n",
      "[2,  6200] loss: 0.013\n",
      "[2,  6300] loss: 0.009\n",
      "[2,  6400] loss: 0.008\n",
      "[2,  6500] loss: 0.002\n",
      "[2,  6600] loss: 0.010\n",
      "[2,  6700] loss: 0.032\n",
      "[2,  6800] loss: 0.019\n",
      "[3,   100] loss: 0.024\n",
      "[3,   200] loss: 0.102\n",
      "[3,   300] loss: 0.243\n",
      "[3,   400] loss: 0.161\n",
      "[3,   500] loss: 0.198\n",
      "[3,   600] loss: 0.154\n",
      "[3,   700] loss: 0.084\n",
      "[3,   800] loss: 0.015\n",
      "[3,   900] loss: 0.016\n",
      "[3,  1000] loss: 0.020\n",
      "[3,  1100] loss: 0.026\n",
      "[3,  1200] loss: 0.037\n",
      "[3,  1300] loss: 0.026\n",
      "[3,  1400] loss: 0.010\n",
      "[3,  1500] loss: 0.005\n",
      "[3,  1600] loss: 0.002\n",
      "[3,  1700] loss: 0.001\n",
      "[3,  1800] loss: 0.001\n",
      "[3,  1900] loss: 0.001\n",
      "[3,  2000] loss: 0.001\n",
      "[3,  2100] loss: 0.001\n",
      "[3,  2200] loss: 0.000\n",
      "[3,  2300] loss: 0.001\n",
      "[3,  2400] loss: 0.001\n",
      "[3,  2500] loss: 0.007\n",
      "[3,  2600] loss: 0.334\n",
      "[3,  2700] loss: 0.355\n",
      "[3,  2800] loss: 0.132\n",
      "[3,  2900] loss: 0.102\n",
      "[3,  3000] loss: 0.026\n",
      "[3,  3100] loss: 0.033\n",
      "[3,  3200] loss: 0.045\n",
      "[3,  3300] loss: 0.020\n",
      "[3,  3400] loss: 0.020\n",
      "[3,  3500] loss: 0.074\n",
      "[3,  3600] loss: 0.111\n",
      "[3,  3700] loss: 0.077\n",
      "[3,  3800] loss: 0.083\n",
      "[3,  3900] loss: 0.107\n",
      "[3,  4000] loss: 0.056\n",
      "[3,  4100] loss: 0.256\n",
      "[3,  4200] loss: 0.041\n",
      "[3,  4300] loss: 0.028\n",
      "[3,  4400] loss: 0.027\n",
      "[3,  4500] loss: 0.021\n",
      "[3,  4600] loss: 0.067\n",
      "[3,  4700] loss: 0.051\n",
      "[3,  4800] loss: 0.031\n",
      "[3,  4900] loss: 0.070\n",
      "[3,  5000] loss: 0.029\n",
      "[3,  5100] loss: 0.012\n",
      "[3,  5200] loss: 0.011\n",
      "[3,  5300] loss: 0.050\n",
      "[3,  5400] loss: 0.087\n",
      "[3,  5500] loss: 0.175\n",
      "[3,  5600] loss: 0.141\n",
      "[3,  5700] loss: 0.064\n",
      "[3,  5800] loss: 0.059\n",
      "[3,  5900] loss: 0.046\n",
      "[3,  6000] loss: 0.051\n",
      "[3,  6100] loss: 0.029\n",
      "[3,  6200] loss: 0.069\n",
      "[3,  6300] loss: 0.086\n",
      "[3,  6400] loss: 0.020\n",
      "[3,  6500] loss: 0.003\n",
      "[3,  6600] loss: 0.007\n",
      "[3,  6700] loss: 0.003\n",
      "[3,  6800] loss: 0.011\n",
      "[4,   100] loss: 0.038\n",
      "[4,   200] loss: 0.014\n",
      "[4,   300] loss: 0.110\n",
      "[4,   400] loss: 0.055\n",
      "[4,   500] loss: 0.011\n",
      "[4,   600] loss: 0.028\n",
      "[4,   700] loss: 0.014\n",
      "[4,   800] loss: 0.011\n",
      "[4,   900] loss: 0.081\n",
      "[4,  1000] loss: 0.026\n",
      "[4,  1100] loss: 0.096\n",
      "[4,  1200] loss: 0.218\n",
      "[4,  1300] loss: 0.149\n",
      "[4,  1400] loss: 0.049\n",
      "[4,  1500] loss: 0.006\n",
      "[4,  1600] loss: 0.014\n",
      "[4,  1700] loss: 0.017\n",
      "[4,  1800] loss: 0.016\n",
      "[4,  1900] loss: 0.170\n",
      "[4,  2000] loss: 0.161\n",
      "[4,  2100] loss: 0.019\n",
      "[4,  2200] loss: 0.036\n",
      "[4,  2300] loss: 0.012\n",
      "[4,  2400] loss: 0.089\n",
      "[4,  2500] loss: 0.063\n",
      "[4,  2600] loss: 0.008\n",
      "[4,  2700] loss: 0.165\n",
      "[4,  2800] loss: 0.026\n",
      "[4,  2900] loss: 0.023\n",
      "[4,  3000] loss: 0.006\n",
      "[4,  3100] loss: 0.014\n",
      "[4,  3200] loss: 0.003\n",
      "[4,  3300] loss: 0.000\n",
      "[4,  3400] loss: 0.001\n",
      "[4,  3500] loss: 0.001\n",
      "[4,  3600] loss: 0.001\n",
      "[4,  3700] loss: 0.000\n",
      "[4,  3800] loss: 0.000\n",
      "[4,  3900] loss: 0.000\n",
      "[4,  4000] loss: 0.000\n",
      "[4,  4100] loss: 0.001\n",
      "[4,  4200] loss: 0.000\n",
      "[4,  4300] loss: 0.000\n",
      "[4,  4400] loss: 0.000\n",
      "[4,  4500] loss: 0.000\n",
      "[4,  4600] loss: 0.000\n",
      "[4,  4700] loss: 0.000\n",
      "[4,  4800] loss: 0.000\n",
      "[4,  4900] loss: 0.000\n",
      "[4,  5000] loss: 0.000\n",
      "[4,  5100] loss: 0.000\n",
      "[4,  5200] loss: 0.001\n",
      "[4,  5300] loss: 0.000\n",
      "[4,  5400] loss: 0.000\n",
      "[4,  5500] loss: 0.000\n",
      "[4,  5600] loss: 0.000\n",
      "[4,  5700] loss: 0.000\n",
      "[4,  5800] loss: 0.000\n",
      "[4,  5900] loss: 0.000\n",
      "[4,  6000] loss: 0.000\n",
      "[4,  6100] loss: 0.000\n",
      "[4,  6200] loss: 0.000\n",
      "[4,  6300] loss: 0.000\n",
      "[4,  6400] loss: 0.000\n",
      "[4,  6500] loss: 0.000\n",
      "[4,  6600] loss: 0.000\n",
      "[4,  6700] loss: 0.000\n",
      "[4,  6800] loss: 0.000\n",
      "[5,   100] loss: 0.000\n",
      "[5,   200] loss: 0.000\n",
      "[5,   300] loss: 0.000\n",
      "[5,   400] loss: 0.000\n",
      "[5,   500] loss: 0.000\n",
      "[5,   600] loss: 0.000\n",
      "[5,   700] loss: 0.000\n",
      "[5,   800] loss: 0.000\n",
      "[5,   900] loss: 0.000\n",
      "[5,  1000] loss: 0.000\n",
      "[5,  1100] loss: 0.000\n",
      "[5,  1200] loss: 0.628\n",
      "[5,  1300] loss: 0.418\n",
      "[5,  1400] loss: 0.093\n",
      "[5,  1500] loss: 0.116\n",
      "[5,  1600] loss: 0.060\n",
      "[5,  1700] loss: 0.046\n",
      "[5,  1800] loss: 0.204\n",
      "[5,  1900] loss: 0.067\n",
      "[5,  2000] loss: 0.088\n",
      "[5,  2100] loss: 0.022\n",
      "[5,  2200] loss: 0.009\n",
      "[5,  2300] loss: 0.035\n",
      "[5,  2400] loss: 0.011\n",
      "[5,  2500] loss: 0.010\n",
      "[5,  2600] loss: 0.028\n",
      "[5,  2700] loss: 0.034\n",
      "[5,  2800] loss: 0.018\n",
      "[5,  2900] loss: 0.007\n",
      "[5,  3000] loss: 0.002\n",
      "[5,  3100] loss: 0.034\n",
      "[5,  3200] loss: 0.027\n",
      "[5,  3300] loss: 0.012\n",
      "[5,  3400] loss: 0.027\n",
      "[5,  3500] loss: 0.018\n",
      "[5,  3600] loss: 0.046\n",
      "[5,  3700] loss: 0.217\n",
      "[5,  3800] loss: 0.122\n",
      "[5,  3900] loss: 0.106\n",
      "[5,  4000] loss: 0.077\n",
      "[5,  4100] loss: 0.093\n",
      "[5,  4200] loss: 0.013\n",
      "[5,  4300] loss: 0.008\n",
      "[5,  4400] loss: 0.002\n",
      "[5,  4500] loss: 0.006\n",
      "[5,  4600] loss: 0.017\n",
      "[5,  4700] loss: 0.136\n",
      "[5,  4800] loss: 0.022\n",
      "[5,  4900] loss: 0.027\n",
      "[5,  5000] loss: 0.046\n",
      "[5,  5100] loss: 0.009\n",
      "[5,  5200] loss: 0.004\n",
      "[5,  5300] loss: 0.016\n",
      "[5,  5400] loss: 0.043\n",
      "[5,  5500] loss: 0.004\n",
      "[5,  5600] loss: 0.036\n",
      "[5,  5700] loss: 0.113\n",
      "[5,  5800] loss: 0.044\n",
      "[5,  5900] loss: 0.062\n",
      "[5,  6000] loss: 0.033\n",
      "[5,  6100] loss: 0.051\n",
      "[5,  6200] loss: 0.027\n",
      "[5,  6300] loss: 0.012\n",
      "[5,  6400] loss: 0.039\n",
      "[5,  6500] loss: 0.020\n",
      "[5,  6600] loss: 0.027\n",
      "[5,  6700] loss: 0.022\n",
      "[5,  6800] loss: 0.061\n",
      "[6,   100] loss: 0.111\n",
      "[6,   200] loss: 0.090\n",
      "[6,   300] loss: 0.109\n",
      "[6,   400] loss: 0.034\n",
      "[6,   500] loss: 0.025\n",
      "[6,   600] loss: 0.044\n",
      "[6,   700] loss: 0.037\n",
      "[6,   800] loss: 0.030\n",
      "[6,   900] loss: 0.043\n",
      "[6,  1000] loss: 0.122\n",
      "[6,  1100] loss: 0.025\n",
      "[6,  1200] loss: 0.005\n",
      "[6,  1300] loss: 0.021\n",
      "[6,  1400] loss: 0.010\n",
      "[6,  1500] loss: 0.033\n",
      "[6,  1600] loss: 0.006\n",
      "[6,  1700] loss: 0.004\n",
      "[6,  1800] loss: 0.000\n",
      "[6,  1900] loss: 0.005\n",
      "[6,  2000] loss: 0.000\n",
      "[6,  2100] loss: 0.000\n",
      "[6,  2200] loss: 0.000\n",
      "[6,  2300] loss: 0.000\n",
      "[6,  2400] loss: 0.000\n",
      "[6,  2500] loss: 0.000\n",
      "[6,  2600] loss: 0.000\n",
      "[6,  2700] loss: 0.000\n",
      "[6,  2800] loss: 0.001\n",
      "[6,  2900] loss: 0.099\n",
      "[6,  3000] loss: 0.193\n",
      "[6,  3100] loss: 0.158\n",
      "[6,  3200] loss: 0.051\n",
      "[6,  3300] loss: 0.154\n",
      "[6,  3400] loss: 0.063\n",
      "[6,  3500] loss: 0.066\n",
      "[6,  3600] loss: 0.039\n",
      "[6,  3700] loss: 0.004\n",
      "[6,  3800] loss: 0.039\n",
      "[6,  3900] loss: 0.011\n",
      "[6,  4000] loss: 0.014\n",
      "[6,  4100] loss: 0.001\n",
      "[6,  4200] loss: 0.006\n",
      "[6,  4300] loss: 0.029\n",
      "[6,  4400] loss: 0.023\n",
      "[6,  4500] loss: 0.051\n",
      "[6,  4600] loss: 0.098\n",
      "[6,  4700] loss: 0.040\n",
      "[6,  4800] loss: 0.053\n",
      "[6,  4900] loss: 0.166\n",
      "[6,  5000] loss: 0.097\n",
      "[6,  5100] loss: 0.111\n",
      "[6,  5200] loss: 0.021\n",
      "[6,  5300] loss: 0.001\n",
      "[6,  5400] loss: 0.005\n",
      "[6,  5500] loss: 0.025\n",
      "[6,  5600] loss: 0.011\n",
      "[6,  5700] loss: 0.042\n",
      "[6,  5800] loss: 0.008\n",
      "[6,  5900] loss: 0.010\n",
      "[6,  6000] loss: 0.019\n",
      "[6,  6100] loss: 0.005\n",
      "[6,  6200] loss: 0.003\n",
      "[6,  6300] loss: 0.003\n",
      "[6,  6400] loss: 0.016\n",
      "[6,  6500] loss: 0.081\n",
      "[6,  6600] loss: 0.002\n",
      "[6,  6700] loss: 0.013\n",
      "[6,  6800] loss: 0.140\n",
      "[7,   100] loss: 0.136\n",
      "[7,   200] loss: 0.077\n",
      "[7,   300] loss: 0.056\n",
      "[7,   400] loss: 0.085\n",
      "[7,   500] loss: 0.015\n",
      "[7,   600] loss: 0.047\n",
      "[7,   700] loss: 0.044\n",
      "[7,   800] loss: 0.007\n",
      "[7,   900] loss: 0.029\n",
      "[7,  1000] loss: 0.060\n",
      "[7,  1100] loss: 0.018\n",
      "[7,  1200] loss: 0.168\n",
      "[7,  1300] loss: 0.042\n",
      "[7,  1400] loss: 0.012\n",
      "[7,  1500] loss: 0.003\n",
      "[7,  1600] loss: 0.010\n",
      "[7,  1700] loss: 0.021\n",
      "[7,  1800] loss: 0.046\n",
      "[7,  1900] loss: 0.095\n",
      "[7,  2000] loss: 0.030\n",
      "[7,  2100] loss: 0.023\n",
      "[7,  2200] loss: 0.027\n",
      "[7,  2300] loss: 0.005\n",
      "[7,  2400] loss: 0.044\n",
      "[7,  2500] loss: 0.265\n",
      "[7,  2600] loss: 0.108\n",
      "[7,  2700] loss: 0.024\n",
      "[7,  2800] loss: 0.026\n",
      "[7,  2900] loss: 0.024\n",
      "[7,  3000] loss: 0.002\n",
      "[7,  3100] loss: 0.001\n",
      "[7,  3200] loss: 0.007\n",
      "[7,  3300] loss: 0.001\n",
      "[7,  3400] loss: 0.001\n",
      "[7,  3500] loss: 0.000\n",
      "[7,  3600] loss: 0.000\n",
      "[7,  3700] loss: 0.001\n",
      "[7,  3800] loss: 0.000\n",
      "[7,  3900] loss: 0.008\n",
      "[7,  4000] loss: 0.005\n",
      "[7,  4100] loss: 0.038\n",
      "[7,  4200] loss: 0.298\n",
      "[7,  4300] loss: 0.109\n",
      "[7,  4400] loss: 0.107\n",
      "[7,  4500] loss: 0.048\n",
      "[7,  4600] loss: 0.139\n",
      "[7,  4700] loss: 0.003\n",
      "[7,  4800] loss: 0.006\n",
      "[7,  4900] loss: 0.002\n",
      "[7,  5000] loss: 0.025\n",
      "[7,  5100] loss: 0.020\n",
      "[7,  5200] loss: 0.002\n",
      "[7,  5300] loss: 0.000\n",
      "[7,  5400] loss: 0.000\n",
      "[7,  5500] loss: 0.009\n",
      "[7,  5600] loss: 0.104\n",
      "[7,  5700] loss: 0.033\n",
      "[7,  5800] loss: 0.006\n",
      "[7,  5900] loss: 0.017\n",
      "[7,  6000] loss: 0.119\n",
      "[7,  6100] loss: 0.202\n",
      "[7,  6200] loss: 0.155\n",
      "[7,  6300] loss: 0.156\n",
      "[7,  6400] loss: 0.057\n",
      "[7,  6500] loss: 0.022\n",
      "[7,  6600] loss: 0.039\n",
      "[7,  6700] loss: 0.040\n",
      "[7,  6800] loss: 0.053\n",
      "[8,   100] loss: 0.032\n",
      "[8,   200] loss: 0.011\n",
      "[8,   300] loss: 0.001\n",
      "[8,   400] loss: 0.005\n",
      "[8,   500] loss: 0.002\n",
      "[8,   600] loss: 0.019\n",
      "[8,   700] loss: 0.003\n",
      "[8,   800] loss: 0.000\n",
      "[8,   900] loss: 0.012\n",
      "[8,  1000] loss: 0.019\n",
      "[8,  1100] loss: 0.024\n",
      "[8,  1200] loss: 0.050\n",
      "[8,  1300] loss: 0.004\n",
      "[8,  1400] loss: 0.001\n",
      "[8,  1500] loss: 0.000\n",
      "[8,  1600] loss: 0.000\n",
      "[8,  1700] loss: 0.000\n",
      "[8,  1800] loss: 0.000\n",
      "[8,  1900] loss: 0.000\n",
      "[8,  2000] loss: 0.000\n",
      "[8,  2100] loss: 0.000\n",
      "[8,  2200] loss: 0.000\n",
      "[8,  2300] loss: 0.000\n",
      "[8,  2400] loss: 0.000\n",
      "[8,  2500] loss: 0.000\n",
      "[8,  2600] loss: 0.000\n",
      "[8,  2700] loss: 0.000\n",
      "[8,  2800] loss: 0.000\n",
      "[8,  2900] loss: 0.000\n",
      "[8,  3000] loss: 0.000\n",
      "[8,  3100] loss: 0.000\n",
      "[8,  3200] loss: 0.000\n",
      "[8,  3300] loss: 0.000\n",
      "[8,  3400] loss: 0.000\n",
      "[8,  3500] loss: 0.000\n",
      "[8,  3600] loss: 0.000\n",
      "[8,  3700] loss: 0.000\n",
      "[8,  3800] loss: 0.000\n",
      "[8,  3900] loss: 0.000\n",
      "[8,  4000] loss: 0.000\n",
      "[8,  4100] loss: 0.000\n",
      "[8,  4200] loss: 0.000\n",
      "[8,  4300] loss: 0.000\n",
      "[8,  4400] loss: 0.000\n",
      "[8,  4500] loss: 0.000\n",
      "[8,  4600] loss: 0.000\n",
      "[8,  4700] loss: 0.000\n",
      "[8,  4800] loss: 0.000\n",
      "[8,  4900] loss: 0.000\n",
      "[8,  5000] loss: 0.000\n",
      "[8,  5100] loss: 0.000\n",
      "[8,  5200] loss: 0.000\n",
      "[8,  5300] loss: 0.000\n",
      "[8,  5400] loss: 0.000\n",
      "[8,  5500] loss: 0.000\n",
      "[8,  5600] loss: 0.016\n",
      "[8,  5700] loss: 0.596\n",
      "[8,  5800] loss: 0.226\n",
      "[8,  5900] loss: 0.104\n",
      "[8,  6000] loss: 0.142\n",
      "[8,  6100] loss: 0.082\n",
      "[8,  6200] loss: 0.101\n",
      "[8,  6300] loss: 0.120\n",
      "[8,  6400] loss: 0.034\n",
      "[8,  6500] loss: 0.067\n",
      "[8,  6600] loss: 0.034\n",
      "[8,  6700] loss: 0.017\n",
      "[8,  6800] loss: 0.022\n",
      "[9,   100] loss: 0.001\n",
      "[9,   200] loss: 0.003\n",
      "[9,   300] loss: 0.018\n",
      "[9,   400] loss: 0.066\n",
      "[9,   500] loss: 0.004\n",
      "[9,   600] loss: 0.007\n",
      "[9,   700] loss: 0.001\n",
      "[9,   800] loss: 0.001\n",
      "[9,   900] loss: 0.000\n",
      "[9,  1000] loss: 0.000\n",
      "[9,  1100] loss: 0.000\n",
      "[9,  1200] loss: 0.000\n",
      "[9,  1300] loss: 0.000\n",
      "[9,  1400] loss: 0.000\n",
      "[9,  1500] loss: 0.021\n",
      "[9,  1600] loss: 0.009\n",
      "[9,  1700] loss: 0.084\n",
      "[9,  1800] loss: 0.076\n",
      "[9,  1900] loss: 0.079\n",
      "[9,  2000] loss: 0.045\n",
      "[9,  2100] loss: 0.029\n",
      "[9,  2200] loss: 0.107\n",
      "[9,  2300] loss: 0.036\n",
      "[9,  2400] loss: 0.062\n",
      "[9,  2500] loss: 0.026\n",
      "[9,  2600] loss: 0.003\n",
      "[9,  2700] loss: 0.027\n",
      "[9,  2800] loss: 0.006\n",
      "[9,  2900] loss: 0.005\n",
      "[9,  3000] loss: 0.016\n",
      "[9,  3100] loss: 0.004\n",
      "[9,  3200] loss: 0.009\n",
      "[9,  3300] loss: 0.003\n",
      "[9,  3400] loss: 0.002\n",
      "[9,  3500] loss: 0.010\n",
      "[9,  3600] loss: 0.003\n",
      "[9,  3700] loss: 0.028\n",
      "[9,  3800] loss: 0.039\n",
      "[9,  3900] loss: 0.127\n",
      "[9,  4000] loss: 0.054\n",
      "[9,  4100] loss: 0.158\n",
      "[9,  4200] loss: 0.251\n",
      "[9,  4300] loss: 0.099\n",
      "[9,  4400] loss: 0.036\n",
      "[9,  4500] loss: 0.025\n",
      "[9,  4600] loss: 0.019\n",
      "[9,  4700] loss: 0.095\n",
      "[9,  4800] loss: 0.004\n",
      "[9,  4900] loss: 0.036\n",
      "[9,  5000] loss: 0.029\n",
      "[9,  5100] loss: 0.039\n",
      "[9,  5200] loss: 0.016\n",
      "[9,  5300] loss: 0.185\n",
      "[9,  5400] loss: 0.038\n",
      "[9,  5500] loss: 0.012\n",
      "[9,  5600] loss: 0.014\n",
      "[9,  5700] loss: 0.005\n",
      "[9,  5800] loss: 0.000\n",
      "[9,  5900] loss: 0.001\n",
      "[9,  6000] loss: 0.001\n",
      "[9,  6100] loss: 0.002\n",
      "[9,  6200] loss: 0.061\n",
      "[9,  6300] loss: 0.013\n",
      "[9,  6400] loss: 0.007\n",
      "[9,  6500] loss: 0.045\n",
      "[9,  6600] loss: 0.006\n",
      "[9,  6700] loss: 0.004\n",
      "[9,  6800] loss: 0.002\n",
      "[10,   100] loss: 0.000\n",
      "[10,   200] loss: 0.000\n",
      "[10,   300] loss: 0.000\n",
      "[10,   400] loss: 0.000\n",
      "[10,   500] loss: 0.027\n",
      "[10,   600] loss: 0.164\n",
      "[10,   700] loss: 0.252\n",
      "[10,   800] loss: 0.142\n",
      "[10,   900] loss: 0.100\n",
      "[10,  1000] loss: 0.054\n",
      "[10,  1100] loss: 0.004\n",
      "[10,  1200] loss: 0.026\n",
      "[10,  1300] loss: 0.017\n",
      "[10,  1400] loss: 0.004\n",
      "[10,  1500] loss: 0.005\n",
      "[10,  1600] loss: 0.024\n",
      "[10,  1700] loss: 0.002\n",
      "[10,  1800] loss: 0.026\n",
      "[10,  1900] loss: 0.002\n",
      "[10,  2000] loss: 0.001\n",
      "[10,  2100] loss: 0.000\n",
      "[10,  2200] loss: 0.000\n",
      "[10,  2300] loss: 0.001\n",
      "[10,  2400] loss: 0.000\n",
      "[10,  2500] loss: 0.000\n",
      "[10,  2600] loss: 0.003\n",
      "[10,  2700] loss: 0.000\n",
      "[10,  2800] loss: 0.001\n",
      "[10,  2900] loss: 0.000\n",
      "[10,  3000] loss: 0.000\n",
      "[10,  3100] loss: 0.000\n",
      "[10,  3200] loss: 0.000\n",
      "[10,  3300] loss: 0.000\n",
      "[10,  3400] loss: 0.000\n",
      "[10,  3500] loss: 0.000\n",
      "[10,  3600] loss: 0.000\n",
      "[10,  3700] loss: 0.000\n",
      "[10,  3800] loss: 0.021\n",
      "[10,  3900] loss: 0.485\n",
      "[10,  4000] loss: 0.159\n",
      "[10,  4100] loss: 0.203\n",
      "[10,  4200] loss: 0.121\n",
      "[10,  4300] loss: 0.100\n",
      "[10,  4400] loss: 0.008\n",
      "[10,  4500] loss: 0.000\n",
      "[10,  4600] loss: 0.000\n",
      "[10,  4700] loss: 0.004\n",
      "[10,  4800] loss: 0.014\n",
      "[10,  4900] loss: 0.034\n",
      "[10,  5000] loss: 0.023\n",
      "[10,  5100] loss: 0.001\n",
      "[10,  5200] loss: 0.007\n",
      "[10,  5300] loss: 0.001\n",
      "[10,  5400] loss: 0.008\n",
      "[10,  5500] loss: 0.001\n",
      "[10,  5600] loss: 0.000\n",
      "[10,  5700] loss: 0.000\n",
      "[10,  5800] loss: 0.000\n",
      "[10,  5900] loss: 0.000\n",
      "[10,  6000] loss: 0.000\n",
      "[10,  6100] loss: 0.003\n",
      "[10,  6200] loss: 0.010\n",
      "[10,  6300] loss: 0.000\n",
      "[10,  6400] loss: 0.164\n",
      "[10,  6500] loss: 0.016\n",
      "[10,  6600] loss: 0.073\n",
      "[10,  6700] loss: 0.138\n",
      "[10,  6800] loss: 0.046\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train cnn\n",
    "data_tensor = torch.Tensor(data).view(-1, 1, 28, 28)  \n",
    "labels_tensor = torch.Tensor(labels).long().squeeze()  \n",
    "\n",
    "\n",
    "dataset = TensorDataset(data_tensor, labels_tensor)\n",
    "data_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10  \n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        \n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 91.79%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97       331\n",
      "           1       0.96      1.00      0.98       432\n",
      "           2       1.00      1.00      1.00       310\n",
      "           3       0.99      0.92      0.95       245\n",
      "           4       0.98      0.98      0.98       498\n",
      "           5       0.94      1.00      0.97       247\n",
      "           6       1.00      0.80      0.89       348\n",
      "           7       0.83      1.00      0.90       436\n",
      "           8       1.00      0.96      0.98       288\n",
      "          10       0.99      0.76      0.86       331\n",
      "          11       1.00      1.00      1.00       209\n",
      "          12       0.84      0.84      0.84       394\n",
      "          13       0.88      0.70      0.78       291\n",
      "          14       0.97      0.85      0.91       246\n",
      "          15       1.00      0.88      0.94       347\n",
      "          16       0.89      1.00      0.94       164\n",
      "          17       0.57      0.86      0.68       144\n",
      "          18       0.81      0.89      0.85       246\n",
      "          19       0.89      0.68      0.77       248\n",
      "          20       0.98      0.92      0.95       266\n",
      "          21       0.94      0.94      0.94       346\n",
      "          22       0.95      1.00      0.97       206\n",
      "          23       0.75      1.00      0.86       267\n",
      "          24       0.97      1.00      0.99       332\n",
      "\n",
      "    accuracy                           0.92      7172\n",
      "   macro avg       0.92      0.92      0.91      7172\n",
      "weighted avg       0.93      0.92      0.92      7172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get accuracy and classification report\n",
    "test_data_tensor = torch.Tensor(test_data).view(-1, 1, 28, 28)\n",
    "test_labels_tensor = torch.Tensor(test_labels).long().squeeze()\n",
    "\n",
    "test_dataset = TensorDataset(test_data_tensor, test_labels_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "net.eval()  \n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():  \n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        \n",
    "        outputs = net(images)\n",
    "\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        \n",
    "        total += labels.size(0)\n",
    "\n",
    "        \n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy : {accuracy:.2f}%')\n",
    "\n",
    "# conv to numpy array\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "print(classification_report(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index: 0.8545731086774213\n"
     ]
    }
   ],
   "source": [
    "ari_cnn = adjusted_rand_score(true_labels, predicted_labels)\n",
    "print(\"Adjusted Rand Index:\", ari_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - Discussion\n",
    "CNN delivered the best accuracy and classification evaluation metrics of our two supervised machine learning models. Of note, label 17/the letter 'R' had far better performance with the CNN than it did with SVM. While there are instances where some evaluation metrics are lower in CNN vs SVM, across the board, CNN gave us better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM - Results\n",
    "- Files are in gmm_traindata and gmm_testdata in the parent repository.\n",
    "\n",
    "We decided to utilize ARI, RI, AIC, BIC, and Silhouette Score regarding GMMs in order to gauge the efficacy of the Sign Language MNIST dataset for ASL. The extended code and analysis is in the aforementioned gmm_traindata and gmm_testdata: the metrics are summarized below. Although this small section deals with only the \"train\" dataset, we also did work on the \"test\" dataset as well, linked up top. Of note, we also tried standardizing the data for GMMs, noted by \"scaled_predicted\". In the interest of time, we decided to just print out values in our final report. As stated earlier, all other information is within the two files. We decided to use the training data from the dataset for our GMM's purposes; this came from a GMM of 5 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-scaled Adjusted Rand Score: 0.04676689255258681\n",
      "Non-scaled Non-Adjusted Rand Score: 0.7703969635432097 \n",
      "\n",
      "Scaled Adjusted Rand Score: 0.023481092716432513\n",
      "Scaled Non-Adjusted Rand Score: 0.769771644446842 \n",
      "\n",
      "aic: 104560606.05819455\n",
      "scaled_aic: -59301488.58365816 \n",
      "\n",
      "bic: 117240621.61718772\n",
      "scaled_bic: -46621473.02466498 \n",
      "\n",
      "silhouette_nonscaled: 0.02272728942562161\n",
      "silhouette_scaled: 0.004961856247034123\n"
     ]
    }
   ],
   "source": [
    "adjusted_rand_nonscaled = 0.04676689255258681\n",
    "non_adjusted_rand_nonscaled = 0.7703969635432097\n",
    "adjusted_rand_scaled = 0.023481092716432513\n",
    "non_adjusted_rand_scaled = 0.769771644446842\n",
    "aic = 104560606.05819455\n",
    "scaled_aic = -59301488.58365816\n",
    "bic = 117240621.61718772\n",
    "scaled_bic = -46621473.02466498\n",
    "silhouette_nonscaled = 0.02272728942562161\n",
    "silhouette_scaled = 0.004961856247034123\n",
    "\n",
    "# NON-SCALED\n",
    "print(\"Non-scaled Adjusted Rand Score:\", adjusted_rand_nonscaled)\n",
    "print(\"Non-scaled Non-Adjusted Rand Score:\", non_adjusted_rand_nonscaled, '\\n')\n",
    "\n",
    "# SCALED\n",
    "print(\"Scaled Adjusted Rand Score:\", adjusted_rand_scaled)\n",
    "print(\"Scaled Non-Adjusted Rand Score:\", non_adjusted_rand_scaled, '\\n')\n",
    "\n",
    "# aic\n",
    "print(\"aic:\", aic)\n",
    "print(\"scaled_aic:\", scaled_aic, '\\n')\n",
    "\n",
    "# bic\n",
    "print(\"bic:\", bic)\n",
    "print(\"scaled_bic:\", scaled_bic, '\\n')\n",
    "\n",
    "# silhouette score\n",
    "print(\"silhouette_nonscaled:\", silhouette_nonscaled)\n",
    "print(\"silhouette_scaled:\", silhouette_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM - Discussion\n",
    "\n",
    "At first glance, our scores were, across the board, very poor, so we also tried scaling the data to see if it'd make any difference; we didn't expect much, and didn't get much. \n",
    "\n",
    "While the non-adjusted Rand scores looked promising for GMM, the adjusted Rand scores were quite bad, at below 0.05 for both the scaled and non-scaled data. This pattern continued with our AIC, BIC, and Silhouette scores: they were all quite horrific. After trying various values of \"n_components\" as well as trying GMM on the test dataset as well, we came to the conclusion that using GMM was a poor fit for our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means - Results (mention how more information can be found at k_means.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means - Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - Results\n",
    "We utilized PCA and and SVM next: this gave us better results than K-Means and GMM but not as good as CNN. This was to be expected, as SVM is a supervised algorithm, which is usually more accurate for our current purposes (image recognition). We did further analysis in the analysis.ipynb file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8581985499163414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       331\n",
      "           1       1.00      1.00      1.00       432\n",
      "           2       0.86      0.99      0.92       310\n",
      "           3       0.92      1.00      0.96       245\n",
      "           4       0.95      1.00      0.97       498\n",
      "           5       0.75      0.84      0.79       247\n",
      "           6       0.94      0.91      0.92       348\n",
      "           7       0.97      0.95      0.96       436\n",
      "           8       0.81      0.90      0.86       288\n",
      "          10       0.83      0.69      0.76       331\n",
      "          11       0.87      0.96      0.91       209\n",
      "          12       0.86      0.75      0.80       394\n",
      "          13       0.90      0.68      0.78       291\n",
      "          14       0.98      0.85      0.91       246\n",
      "          15       1.00      1.00      1.00       347\n",
      "          16       1.00      0.99      1.00       164\n",
      "          17       0.35      0.62      0.45       144\n",
      "          18       0.73      0.83      0.77       246\n",
      "          19       0.84      0.69      0.76       248\n",
      "          20       0.69      0.68      0.69       266\n",
      "          21       0.82      0.65      0.73       346\n",
      "          22       0.65      0.81      0.72       206\n",
      "          23       0.84      0.81      0.83       267\n",
      "          24       0.85      0.76      0.80       332\n",
      "\n",
      "    accuracy                           0.86      7172\n",
      "   macro avg       0.85      0.85      0.84      7172\n",
      "weighted avg       0.87      0.86      0.86      7172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Separate features (pixels) and labels (alphabet)\n",
    "X_train = train.drop('label', axis=1)\n",
    "y_train = train['label']\n",
    "\n",
    "X_test = test.drop('label', axis=1)\n",
    "y_test = test['label']\n",
    "\n",
    "# Normalize pixel values to range [0, 1]\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "svm = SVC(kernel='rbf', gamma='scale', C=1.0)\n",
    "svm.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = svm.predict(X_test_pca)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Perform  PCA on test data\n",
    "X_test_data_pca = pca.transform(X_test)\n",
    "\n",
    "# Predict labels for test data\n",
    "predicted_alphabet = svm.predict(X_test_data_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index: 0.7778209570380875\n"
     ]
    }
   ],
   "source": [
    "ari = adjusted_rand_score(y_test, y_pred)\n",
    "print(\"Adjusted Rand Index:\", ari)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - Discussion\n",
    "As is evident from the get-go, SVM performs considerably better than K-Means and GMM. Especially with regards to GMM, our ARI was over 15 times higher. This is also evident with what we see in our classification report averages: our macro and weighted averages for precision, recall, and f1-score are relatively high, as well as our accuracy. Of interesting note: label 17, or the letter \"R\", struggled a lot, with the lowest scores across all classification categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n",
    "We wouldn't say that there were any inherent problems with the work, but we did have a feeling beforehand that the supervised algorithms would perform better than the unsupervised algorithms for our purposes (image recognition), but we were somewhat surprised at just how poorly they performed with our MNIST drop-in dataset. \n",
    "\n",
    "In this instance, we'd say that more data (at least, in regards to image recognition) would not change the nature of the problem. In most cases, CNN algorithms/CNN models will always have great performance at image recognition, as well as SVM (not to the same extent). Adding more data won't change the general predicted outcome.\n",
    "\n",
    "We believe that exploring additional hyperparameters, had we had more time, would be interesting but wouldn't make a large difference in terms of model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethics & Privacy\n",
    "\n",
    "Our American Sign Language recognition research project utilises the MNIST dataset of hand signs. Even though this dataset has been fairly corroborated and extensively updated over the years; since our project has an application in helping the \"hard of hearing\", it's necessary to consider some possible ethical concerns:\n",
    "\n",
    "1. Clustering Algorithm Bias: The MNIST training data might lack diversity in hand shapes, skin tones, signing styles, or individual variations, resulting in the algorithm prioritising majority patterns, leading to inaccurate classifications for underrepresented groups. For instance, a dataset skewed towards younger signers might struggle with recognizing signs used more frequently by older adults. In addition to this, even with a perfect algorithm also, there might be implicit biases in the dataset which are being amplified by our clustering algorithm.For example, the data might contain more examples of right-handed signing, potentially impacting the model's ability to recognize signs performed with the left hand. While such conclusions are less often, they are important to take under consideration because the implications of such biases are significant. Misclassifications can lead to communication breakdowns, and misunderstandings, all of which on an extended period and a larger sample space may even lead to social exclusion for specific groups within the Deaf community. We aim to address these concerns by trialling and testing the usage of different clustering algorithms to mitigate the risk of false clustering. Hierarchical clustering, for instance, builds a hierarchy of clusters, allowing me to zoom in on specific signing styles or hand shapes potentially underrepresented in the data. Similarly, density-based methods like DBSCAN focus on identifying clusters based on data density, making them less susceptible to the influence of majority patterns that could amplify bias. By evaluating these alternative algorithms with diverse test sets and fairness metrics (accuracy, precision and F1 score), we will choose the model that best balances inclusivity and accuracy, ensuring equitable representation across all user groups.\n",
    "\n",
    "2. Data Privacy Issue: The MNIST Hand Sign dataset we are utilising contains 27,455 cases of test data. These are real-life pictures collected from different thousands of different people. Now, in high-security stakes, hand-pictures also serve as identifiers. Due to this reason, similar to any other dataset, our MNIST ASL dataset is also subject to the protection of the privacy of individuals. In addition to this, we will also have input data from voluntary non-ASL communicators to test the real-time interpretation feature of the app. We hope to address this by keeping the identity of the volunteers undisclosed. In addition, we do it by utilising a \"black-box\" way of allowing the user to interact with the model. Without giving them any information about existing ASL hand signs, we hope to test the model for its accuracy in identifying any or all signs that people make, closest to an actual ASL sign.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "\n",
    "<a name=\"onenote\"></a>1.[^](#one): Ashley Chow, Glenn Cameron, Manfred Georg, Mark Sherwood, Phil Culliton, Sam Sepah, Sohier Dane, Thad Starner. (2023). Google - American Sign Language Fingerspelling Recognition. Kaggle. https://kaggle.com/competitions/asl-fingerspelling<br> \n",
    "\n",
    "<a name=\"twonote\"></a>2.[^](#two): El Moujahid, K. (2021, December 1). Machine learning to make sign language more accessible. Google. https://blog.google/outreach-initiatives/accessibility/ml-making-sign-language-more-accessible/<br> \n",
    "\n",
    "<a name=\"threenote\"></a>3.[^](#three): Garimella, M. (2022, August 23). Sign Language Recognition with Advanced Computer Vision. Medium. https://towardsdatascience.com/sign-language-recognition-with-advanced-computer-vision-7b74f20f3442<br> \n",
    "\n",
    "<a name=\"fournote\"></a>4.[^](#four): tecperson. (October 2017). Sign Language MNIST. Kaggle. https://www.kaggle.com/datasets/datamunge/sign-language-mnist<br> \n",
    "\n",
    "<a name=\"fivenote\"></a>5.[^](#five): Pathan, R. K., Biswas, M., Yasmin, S., Khandaker, M. U., Salman, M., & Youssef, A. A. F. (2023). Sign language recognition using the fusion of image and hand landmarks through multi-headed convolutional neural network. Scientific Reports, 13(1), 16975. https://doi.org/10.1038/s41598-023-43852-x<br> \n",
    "\n",
    "<a name=\"sixnote\"></a>6.[^](#six): Chen, Y. (2023, December 29). Learning American Sign Language (ASL) with Googles Teachable Machine: A No-Code Experiment. Medium. https://medium.com/@dynotes/breaking-barriers-using-googles-no-code-approach-for-sign-language-recognition-and-learning-fc92ae16522c#bypass<br> \n",
    "\n",
    "\"<a name=\"MLTeaching\"></a>7.[^](#MLTeachingNote) Google open Teachable Machine. https://teachablemachine.withgoogle.com/train/tiny_image\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
